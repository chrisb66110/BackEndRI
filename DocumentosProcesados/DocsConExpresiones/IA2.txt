 el secreto ms oscuro de la inteligencia artificial por qu hace lo que hace mit technology review pasar al contenido principal secciones biomedicina computacin energa mvil negocios robtica 10 tecnologas emergentes las 50 empresas ms inteligentes opinin habla el mercado innovadores a fondo actualidad innovadores ms eventos formulario de bsqueda menu suscribirse arrow buscar secciones biomedicina computacin energa mvil negocios robtica 10 tecnologas emergentes las 50 empresas ms inteligentes opinin habla el mercado innovadores a fondo actualidad innovadores ms eventos escriba las palabras clave computacin el secreto ms oscuro de la inteligencia artificial por qu hace lo que hace 1 por muy buenas que sean las predicciones del aprendizaje profundo nadie sabe cmo llega a sus conclusiones este hecho est empezando a generar un problema de confianza y las herramientas para resolverlo no estn ayudando demasiado pero tal vez as es la propia naturaleza de la inteligencia por will knight traducido por teresa woods 17 abril 2017 el ao pasado un extrao coche autnomo fue liberado en las tranquilas calles de monmouth county el prototipo que fue desarrollado por investigadores del fabricante de chips nvidia no tena un aspecto muy distinto al resto de coches autnomos y sin embargo no se pareca a nada de lo que han hecho google tesla o general motors adems era una prueba del poder cada vez mayor de la inteligencia artificial el coche no segua las indicaciones de un ingeniero o un programador en su lugar dependa de un algoritmo que se haba enseado a conducir a s mismo al observar a un conductor humano hacer que el coche aprendiera a conducir bajo este enfoque fue una hazaa impresionante pero tambin resulta algo desconcertante ya que no est claro cul es su mecanismo para la toma de deciciones los datos que recogen los sensores del vehculo entran directamente en una enorme red de neuronas artificiales que los procesan a partir de ellos el ordejador decide qu har y envia las rdenes correspondientes al volante los frenos y otros sistemas para que las lleven a cabo el resultado parece igualar el comportamiento que se esperara de un conductor humano pero y si algn da hiciera algo inesperado como chocar contra un rbol o quedarse inmvil ante un semforo en verde tal y como estn las cosas ahora mismo podra resultar difcil averiguar por qu hace lo que hace el sistema es tan complejo que incluso los ingenieros que lo disearon podran ser incapaces de aislar la razn de cualquier accin determinada y no se le puede preguntar no existe ninguna manera obvia de disear un sistema para que pueda explicar el por qu de lo que ha hecho se acab la confianza ciega la inteligencia artificial debe explicar cmo funciona la misteriosa mente de este vehculo seala un problema cada vez ms palpable de la inteligencia artificial la tecnologa de ia del coche conocida como aprendizaje profundo ha tenido mucho xito resolviendo problemas en los ltimos aos y cada vez se usa ms en labores como generar subttulos reconocer la voz y traducir idiomas estas mismas tcnicas podran llegar a ser capaces de diagnosticar enfermedades mortales tomar decisiones burstiles multimillonarias y transformar industrias al completo pero esto no suceder no a menos que consigamos que las tcnicas como el aprendizaje profundo resulten ms comprensibles para sus creadores y rindan cuentas ante los usuarios en caso contrario resultar difcil predecir cundo se podran producir fallos los cuales son inevitables este es uno de los motivos por los que el coche de nvidia an es experimental ya se estn empleando modelos matemticos para ayudar a determinar quin recibe la libertad condicional quin es apto para obtener prstamos y quin es contratado para ocupar un puesto vacante si se pudiese acceder a estos modelos matemticos sera posible entender su razonamiento pero los bancos el ejrcito y los empleadores estn centrndose en enfoques de aprendizaje automtico an ms complejos que podran resultar totalmente inescrutables el aprendizaje profundo el ms comn de estos enfoques representa una manera fundamentalmente distinta de programar los ordenadores ya es un problema relevante y lo va a ser mucho ms en el futuro afirma el profesor del instituto tecnolgico de massachusetts tommi jaakkola que trabaja en aplicaciones del aprendizaje automtico el experto aade si es una decisin de inversin mdica o militar nadie quiere tener que depender de un mtodo de caja negra ya hay argumentos que defienden que la capacidad de interrogar a un sistema de inteligencia artificial sobre cmo lleg a sus conclusiones representa un derecho legal bsico a partir del verano de 2018 la unin europea podra obligar a las empresas a que ofrezcan una respuesta a sus ususarios sobre las decisiones a las que llegan los sistemas automatizados esto podra resultar imposible incluso para sistemas aparentemente sencillos como las apps y pginas web que emplean el aprendizaje profundo para mostrar anuncios y recomendar canciones los ordenadores que ejecutan esos servicios se han autoprogramado y ni siquiera sabemos cmo incluso los ingenieros que desarrollan estas apps son incapaces de explicar totalmente su comportamiento esto suscita algunas preguntas inquietantes a medida que la tecnologa avance podramos cruzar un umbral a partir del cual utilizar la ia requiera un salto de fe claro que los humanos no siempre podemos explicar realmente nuestros procesos cognitivos tampoco pero encontramos maneras de confiar en y juzgar a la gente de forma intuitiva tambin ser posible eso con mquinas que piensan y toman decisiones de manera distinta a los humanos nunca habamos desarrollado mquinas que trabajan sin que sus creadores entiendan cmo esperamos llevarnos y comunicarnos bien con mquinas inteligentes que podran ser impredecibles e inescrutables estas preguntas me empujaron a emprender un viaje hasta la frontera de las investigaciones sobre algoritmos de inteligencia artificial desde google hasta apple pasando por muchos sitios entre medias incluida una reunin con uno de los grandes filsofos de nuestro tiempo foto el artista adam ferriss cre esta imagen y la de ms abajo con el uso de google deep dream un programa que ajusta una imagen para simular las capacidades de reconocimiento de patrones de una red neuronal profunda las imgenes fueron producidas por una capa intermedia de la red neuronal crdito adam ferriss en 2015 un grupo de investigadores del hospital monte sina de nueva york quiso aplicar el aprendizaje profundo a la vasta base de datos de historiales de pacientes del hospital este conjunto de datos incluye cientos de variables procedentes de los resultados de pruebas consultas mdicas y mucho ms el programa resultante que los investigadores llamaron deep patient fue entrenado con datos de alrededor de 700 000 individuos y cuando fue probado con historiales nuevos result ser increblemente bueno a la hora de precedir enfermedades sin ninguna formacin por parte de expertos deep patient haba descubierto patrones ocultos dentro de los datos del hospital que parecan indicar cundo la gente estaba a punto de desarrollar un amplio abanico de trastornos incluido el cncer de hgado hay muchos mtodos para predecir enfermedades a partir del historial mdico de un paciente que rinden segn el lder del equipo joel dudley pero aade simplemente era mucho mejor elaborar estos modelos pero no sabemos cmo al mismo tiempo deep patient es algo desconcertante parece anticipar el comienzo de trastornos psiquitricos como la esquizofrenia bastante bien pero dado que es un trastorno que a los mdicos les cuesta mucho predecir dudley no entenda los resultados de su algoritmo y sigue sin hacerlo la nueva herramienta da pistas sobre cmo lo hace si algo como deep patient puede ayudar a los mdicos lo ideal sera que compartiera el razonamiento que le ha llevado hasta su prediccin para asegurarse de que es precisa y poder justificar por ejemplo un cambio en la medicacin que recibe un paciente con una sonrisa algo triste dudley afirma desarrollar estos modelos pero no sabemos cmo la inteligencia artificial no siempre ha sido as desde un principio ha habido dos escuelas de pensamiento respecto a lo entendible o explicable que debera ser muchos crean que tena sentido desarrollar mquinas que razonaran de acuerdo a reglas y lgica lo que volvera transparente su funcionamiento interno para cualquiera que quisiera examinar el cdigo otros sentan que la inteligencia avanzara ms si las mquinas se inspiraran en la biologa y aprendieran mediante la observacin y la experiencia esto significaba invertir la programacin informtica en lugar de que un programador escribiera los comandos para resolver un problema el programa genera su propio algoritmo en base a datos de ejemplo y el resultado deseado las tcnicas de aprendizaje automtico que evolucionaron para convertirse en los sistemas de ia ms potentes de la actualidad siguieron el segundo camino bsicamente la mquina se autoprograma al principio este enfoque no tena demasiadas aplicaciones y durante las dcadas de 1960 y 1970 segua ocupando la periferia del campo entonces la informatizacin de muchas industrias y la llegada del big data renovaron el inters eso inspir el desarrollo de tcnicas de aprendizaje automtico ms potentes especialmente nuevas versiones de una tcnica conocida como red neuronal artificial para finales de la dcada de 1990 las redes neuronales podan digitalizar automticamente caracteres escritos a mano pero no fue hasta principios de esta dcada tras varios ingeniosos ajustes y refinamientos cuando las redes neuronales muy grandes o empezaron a ofrecer drsticas mejoras en la percepcin automatizada el aprendizaje profundo es responsable de la explosin actual de la ia ha dotado los ordenadores de poderes extraordinarios como la capacidad de reconocer las palabras habladas casi igual de bien que cualquier persona algo demasiado complejo para ser codificado a mano el aprendizaje profundo ha transformado la visin de mquinas y mejorado muchsimo la traduccin automatizada ya contribuye en la toma de todo tipo de decisiones claves en la medicina las finanzas la fabricacin y mucho ms el funcionamiento de cualquier tecnologa de aprendizaje automtico es inherentemente ms opaco que un sistema codificado a mano incluso para los informticos esto no quiere decir que todas las futuras tcnicas de ia vayan a resultar igual de imposibles de entender pero por su naturaleza el aprendizaje profundo es una caja negra especialmente oscura simplemente no es posible adentrarse en las entraas de una red neuronal profunda para comprobar cmo funciona su razonamiento est arraigado en el comportamiento de miles de neuronas simuladas dispuestas en docenas o incluso cientos de capas intricadamente interconectadas las neuronas de la primera capa reciben informaciones como la intensidad de un pxel dentro de una imagen y despus realizan un clculo antes de emitir una nueva seal estas seales alimentan las neuronas de la prxima capa de una compleja red y as sucesivamente hasta generar un resultado final adems hay un proceso conocido como propagacin hacia atrs que ajusta los clculos de neuronas individuales para que la red aprenda a producir un resultado deseado las mltiples capas de una red profunda la habilitan para reconocer cosas a muchos niveles distintos de abstraccin en un sistema diseado para reconocer perros por ejemplo las primeras capas reconocen elementos muy bsicos como contornos y colores las siguientes capas reconocen cosas ms complejas como el pelo o los ojos y las capas superiores objetos al completo como un perro el mismo enfoque puede aplicarse a otras reas que permiten que las mquinas se enseen a s mismas los sonidos que componen las palabras dentro del habla las letras y palabras que generan frases dentro de un texto o los movimientos de volante requeridos para la conduccin podra ser una parte de la propia naturaleza de la inteligencia el hecho de que slo una fraccin est sujeta a explicaciones racionales parte de ella es simplemente se han empleado ingeniosas estrategias para intentar captar y explicar en mayor detalle lo que sucede dentro de estos sistemas en 2015 unos investigadores de google modificaron un algoritmo de reconocimiento de imgenes por aprendizaje profundo para que en lugar de divisar objetos dentro de las fotos los generara o modificara al ejecutar el algoritmo al revs descubrieron las caractersticas que el programa emplea para reconocer un pjaro o un edificio las imgenes resultantes producidas por un proyecto conocido como deep dream mostraban animales grotescos con aspecto aliengena emergiendo de nubes y plantas y pagodas alucinatorias que poblaban bosques y cordilleras las imgenes demostraron que el aprendizaje profundo no tiene por qu ser del todo inescrutable revelaron que los algoritmos se centran en caractersticas visuales familiares como el pico o las plumas de un pjaro pero las imgenes tambin ofrecieron pistas de lo mucho que difiere de la percepcin humana ya que podran tomar decisiones basadas en elementos que nosotros sabramos ignorar los investigadores de google sealaron que cuando su algoritmo generaba imgenes de una mancuerna tambin generaba un brazo humano sujetndola la mquina haba concluido que el brazo formaba parte del objeto y la neurociencia y la ciencia cognitiva han logrado an ms avances un equipo liderado por el profesor adjunto de la universidad de wyoming jeff clune ha empleado el equivalente de ia de las ilusiones pticas para probar redes neuronales profundas en 2015 el grupo de clune demostr cmo ciertas imgenes podan engaar a una red para percibir cosas que no estaban all porque las imgenes se aprovechan de los patrones de nivel bajo que el sistema rastrea uno de los colaboradores de clune jason yosinski tambin desarroll una herramienta que acta como sonda cerebral se dirige a cualquier neurona de la red y busca la imagen que ms la active las imgenes devueltas son abstractas una versin impresionista de un flamenco o autobs lo que de nuevo revela la naturaleza misteriosa de las capacidades de percepcin de la mquina foto esta temprana red neuronal artificial del laboratorio aeronutica de la universidad de cornell en bfalo nueva york de alrededor de 1960 procesaba informaciones procedentes de sensores de luz crdito frederic lewis foto ferriss se sinti inspirado a pasar la red neuronal artificial de la universidad de cornell por deep dream generando as esta imagen y la de ms abajo crdito adam ferriss pero no podemos conformarnos con una visin aproximada de cmo funciona la inteligencia artificial y parece que no hay soluciones fciles lo que resulta crucial para reconocer patrones y tomar decisiones complejas de nivel superior es la interaccin de clculos dentro de una red neuronal profunda pero esos clculos son una cinaga de funciones y variables matemticas tuvieras una red neuronal muy pequea tal vez podras entenderla pero en cuanto se vuelve muy grande y presenta miles de unidades por capa y tal vez cientos de capas entonces se vuelve bastante dice jaakkola en el despacho de al lado al de jaakkola trabaja la profesora del mit regina barzilay que est empeada en aplicar el aprendizaje automtico a la medicina fue diagnosticada con cncer de mama hace un par de aos a la edad de 43 el diagnstico le result impactante pero barzilay tambin estaba consternada por el hecho de que los mtodos estadsticos ms modernos y el aprendizaje automtico no estuvieran siendo empleados para apoyar las investigaciones oncolgicas ni para guiar los tratamientos de los pacientes asegura que la ia tiene un enorme potencial para revolucionar la medicina pero alcanzar ese potencial significar ir ms all de los historiales mdicos le gustara que se emplearan muchos ms datos los cuales asegura que estn infrautilizados de imgenes datos patolgicos todas estas aclara esperamos llevarnos y comunicarnos bien con mquinas inteligentes que podran ser impredecibles e inescrutables despus de finalizar su tratamiento el ao pasado barzilay y sus alumnos empezaron a colaborar con mdicos del hospital general de massachusetts para desarrollar un sistema capaz de minar los informes de patologas para identificar pacientes con determinadas caractersticas que los investigadores tal vez querran estudiar sin embargo barzilay entenda que el sistema tendra que explicar su razonamiento as que junto con jaakkola y un alumno aadi un paso el sistema extrae y seala las partes de un texto que ms representan el patrn que ha descubierto barzilay y sus alumnos tambin estn desarrollando un algoritmo de aprendizaje profundo capaz de identificar las primeras seales del cncer de mama en imgenes de mamografa y quieren dotarlo de la capacidad de explicar su razonamiento necesitas tener un bucle de colaboracin entre la mquina y el explica barzilay el ejrcito de estados unidos est invirtiendo miles de millones de euros en proyectos que emplearn el aprendizaje automtico para pilotar vehculos y aeronaves identificar objetivos y ayudar a los analistas a procesar enormes cantidades de datos de inteligencia aqu ms que en ningn otro sitio incluso ms que en la medicina existe poco margen para los misterios algortmicos y el departamento de defensa de eeuu considera que la incapacidad de explicarse es un obstculo clave el director de programa de la agencia de proyectos de investigacin avanzados de eeuu por sus siglas en david gunning est supervisando el muy bien nombrado programa de inteligencia artificial explicable este veterano de la agencia de pelo gris y que supervis el proyecto de darpa que finalmente dio paso a la creacin de siri dice que la automatizacin se est colando en innumerables reas del ejrcito analistas de inteligencia estn probando el aprendizaje automtico para identificar patrones en vastas cantidades de datos de vigilancia muchos vehculos autnomos terrestres y areos estn siendo desarrollados y probados pero los soldados probablemente no se sentirn cmodos dentro de un tanque robtico del que no saben por qu hace lo que hace y los analistas se mostrarn reacios a actuar en funcin de unas recomendaciones generadas sin algn tipo de razonamiento menudo estos sistemas generan muchas falsas alarmas por lo que un analista de inteligencia realmente necesita una ayuda extra para entender por qu se ha hecho una seala gunning el pasado mes de marzo darpa escogi 13 proyectos de la academia y la industria para financiarlos bajo el programa de gunning algunos de ellos podran basarse en el trabajo liderado por el profesor de la universidad de washington carlos guestrin junto a sus compaeros ha desarrollado una manera de que los sistemas de aprendizaje automtico expliquen sus resultados en esencia bajo este mtodo un ordenador encuentra automticamente unos pocos ejemplos dentro de un conjunto de datos y proporciona una corta explicacin para ellos un sistema diseado para clasificar un mensaje de correo electrnico como procedente de un terrorista por ejemplo podra emplear millones de mensajes en su entrenamiento y proceso de toma de decisiones pero mediante el enfoque del equipo de washington podra sealar determinadas palabras claves encontradas dentro de un mensaje el grupo de guestrin tambin ha elaborado herramientas para que los sistemas de reconocimiento de imgenes den pistas sobre su razonamiento al sealar las partes de una imagen que resultaron ms importantes pero estos enfoques tienen una pega las explicaciones siempre estarn simplificadas lo que significa que algunas informaciones vitales podran perderse por el camino guestrin detalla hemos logrado el sueo al completo que es donde la ia mantiene una conversacin contigo y es capaz de explicarse an estamos muy lejos de disponer de una ia verdaderamente interpretable y no es necesario que se trate de temas cruciales como el diagnstico de un cncer para que esto resulte un problema conocer el razonamiento de la ia tambin ser imprescindible si la tecnologa aspira a formar parte de la vida diaria de las personas el lder del equipo de siri de apple tom gruber dice que el carcter explicable es una consideracin clave para su equipo en sus esfuerzos por hacerla ms inteligente y hbil gruber no quiso hablar de planes especficos para el futuro de siri pero resulta fcil imaginar que al recibir una recomendacin de un restaurante se quiera conocer el razonamiento subyacente el director de investigaciones de ia de apple y profesor de la universidad de carnegie mellon ruslan salakhutdinov considera que la capacidad de explicarse es el ncleo de la relacin en evolucin entre los humanos y las mquinas inteligentes a generar afirma al igual que muchos aspectos del comportamiento humano resultan imposibles de explicar en detalle tal vez no ser posible que la inteligencia artificial llegue a explicar todo lo que hace si alguien te puede dar una explicacin razonable sus probablemente estar incompleta y lo mismo podra aplicarse a la inteligencia sugiere clune el experto aade podra ser una parte de la propia naturaleza de la inteligencia el hecho de que slo una fraccin est sujeta a explicaciones racionales parte de ella es simplemente instintiva o subconsciente o en tal caso tal vez llegue un momento en el que debamos decidir si confiamos ciegamente en la ia o desechamos su uso igualmente esa misma decisin tendr que incorporar inteligencia social al igual que la sociedad se construye sobre una base de comportamientos aceptables necesitaremos disear los sistemas de ia para respetar y encajar con nuestras normas sociales si vamos a crear tanques robticos y otras mquinas de matar es importante que su toma de decisiones concuerde con nuestros juicios ticos para explorar estos conceptos metafsicos acud a la universidad de tufts para reunirme con el filsofo de renombre y cientfico cognitivo daniel dennett que estudia la consciencia y la mente un captulo de su ltimo libro from bacteria to bach and back un tratado enciclopdico sobre la consciencia sugiere que una parte natural de la evolucin de la propia inteligencia consiste en desarrollar sistemas capaces de ejecutar tareas que sus creadores son incapaces de ejecutar pregunta es qu adaptaciones tenemos que hacer para hacerlo bien qu estndares debemos exigirles que cumplan a ellos y a nosotros mismos me pregunta dentro de su abarrotado despacho en el idlico campus de la universidad tambin me hizo una advertencia sobre la bsqueda del carcter explicable que si vamos a utilizar estas cosas y depender de ellas entonces necesitamos el mejor entendimiento posible de cmo y por qu nos proporcionan sugiere pero puesto que podra no existir ninguna respuesta perfecta deberamos mostrarnos igual de cautelosos ante las explicaciones de la ia como nos mostramos ante las explicaciones humanas independientemente de lo lista que parezca la mquina dennet concluye no puede explicar lo que hace mejor que nosotros entonces no te crditos ilustracin keith rankin su nombre comment computacin las mquinas cada vez ms potentes estn acelerando los avances cientficos los negocios y la vida cmo afrontar que internet no ha conseguido crear un mundo mejor los grandes defensores de la web que confiaban plenamente en su capacidad para mejorar la sociedad se han topado con una cruda realidad de noticias falsas odio y falta de privacidad que les ha dividido en cuatro grandes grupos de pensamiento puristas esperanzados desilusionados y revisionistas por tim hwang el uber de la ciberseguridad une a empresas con cazadores de virus ante el aumento de ciberataques y la falta de personal cualificado cada vez ms compaas recurren a estos servicios para que expertos en ciberseguridad freelance les ayuden a detectar errores en sus cdigos a cambio de recompensas econmicas los mejores pueden ganar sumas importantes por martin giles crear noticias falsas al alcance de cualquiera gracias a la ia los avances en aprendizaje automtico han hecho posible el desarrollo de herramientas para crear vdeos falsos cada vez ms verosmiles este hecho sumado a que estas herramientas son cada vez ms accesibles plantean un futuro en el que el anlisis por parte de los expertos ser fundamental para saber si se trata de realidad o de manipulacin por will knight ms informacin sobre computacin sguenos twitter facebook rss compaa quines somos contctenos legal poltica de privacidad trminos y condiciones copyright mit technology review 2017 2018 usamos cookies en este sitio para mejorar la experiencia de usuario al hacer clic en cualquier enlace de esta pgina nos da su consentimiento para utilizar cookies de acuerdo ms info 