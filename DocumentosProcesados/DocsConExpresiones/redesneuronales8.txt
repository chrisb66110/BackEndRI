 redes neuronales una visi superficial fernando sancho caparrini fernando sancho caparrini inicio docencia inteligencia artificial 2018 19 l inform tica 2018 19 icsr mdsbd 2018 19 trabajos fin de grado dirigidos trabajos fin de m ster dirigidos docencia actual docencia anterior estalmat instrucciones netlogo programaci declarativa 2016 17 inteligencia artificial 2017 18 l inform tica 2017 2018 slaem maes 2017 2018 icsr mdsbd 2017 2018 cursos inteligencia artificial teor de la computabilidad programaci con netlogo modelado y an lisis de la complejidad deep learning investigaci sistemas complejos aprendizaje autom tico modelado cultural teor algor de la informaci computaci natural seminario tesis doctorales dirigidas proyectos participaci en proyectos de investigaci cultureplex lab an lisis del patrimonio cultural ecuatoriano hispanic baroque project modelos de netlogo publicaciones art comunicaciones libros otros entradas seminario y llegamos al 4 no me ense m s postales dame de la resoluci proposicional a la metaheur para b y metaheur para b y descubrimiento de conocimiento en modelado de sistemas din micos con seminario y ya van tres resolviendo problemas de nuevo bloque de cursos introducci a la l difusa simulated annealing in netlogo b estoc sticas templado introducci a y representaci del conocimiento fundamentos matem ticos del machine seminario nueva temporada la tiran de las publicaciones entrenamiento de redes neuronales complex networks toolbox por temas inteligencia artificial metaheur para b y metaheur para b y descubrimiento de conocimiento en modelado de sistemas din micos con algoritmo de montecarlo aplicado a resolviendo problemas de nuevo bloque de cursos introducci a la l difusa simulated annealing in netlogo b estoc sticas templado introducci a y representaci del conocimiento fundamentos matem ticos del machine entrenamiento de redes neuronales usando patches de netlogo para problemas de satisfacci de self organizing maps in netlogo artificial neural networks in netlogo local search algorithms in netlogo a general solver in netlogo a general bfs solver in netlogo curso acelerado de l proposicional aprendizaje por refuerzo algoritmo q minimax juegos con adversario m combinados de aprendizaje aprendizaje inductivo de sistemas basados en reglas ejercicios l difusa ejercicios minimax an lisis formal de conceptos mapas auto organizados clasificaci supervisada y no introducci al aprendizaje autom tico optimizaci en el espacio de redes neuronales una visi ejercicios de pso y aco algoritmos de hormigas y el problema pso optimizaci por enjambres de fractales aut celulares ejercicios redes complejas introducci a las redes complejas sistemas complejos sistemas ejercicios inteligencia colectiva sistemas colectivos inteligencia ejercicios de b locales algoritmos gen b locales ejercicios de b informada b informadas b no informadas ejercicios de b no informada espacios de estados ejercicios netlogo ii ejercicios de algoritmos gen ejercicios de l de primer orden ejercicios de l proposicional ejercicios netlogo i sistemas multiagente y simulaci el modelado de problemas programaci funcional se puede liberar la programaci elm creaci r pida de elm proyecto juego c se demuestra que un programa es programaci funcional reactiva haskell el lenguaje funcional programaci funcional una mirada elm definiendo tipos para modelar elm sintaxis b sica elm se elm introducci ejercicios de elm ejercicios de elm refactorizaci funcional elm elementos visuales modelos netlogo algoritmo de montecarlo aplicado a nuevo bloque de cursos simulated annealing in netlogo complex networks toolbox netlogo interfaz gr fica netlogo procedimientos an netlogo conjuntos de agentes usando patches de netlogo para netlogo conceptos b sicos cuadernos del cis simulaci basada programming mathematical models classical elements in netlogo fire classical elements in netlogo water classical elements in netlogo earth self organizing maps in netlogo artificial neural networks in netlogo local search algorithms in netlogo a general solver in netlogo a general bfs solver in netlogo netlogo una herramienta de modelado opini no me ense m s postales dame qu hay detr s de los dobles grados la tiran de las publicaciones emprendimiento descabezado puede existir matem tica sin un secreto de pasillo opini 141 de doron zeilberger sobre el modelado usando ecuaciones el auge de un joven paradigma the crisis in higher education el imparable ascenso de la educaci cuando la religi pisa el c algunos comentarios sobre la por qu falla el capitalismo objetivos de i math buscar palabras usadas en entradas y p ginas de este sitio introduzca aqui a buscar netlogo book english and spanish the new book to learn netlogo chapters going from the basics to advanced features exercises proposed in every chapter and full examples los m s le 1 clasificaci supervisada y no supervisada 2 algoritmos de hormigas y el problema del viajante 3 introducci al aprendizaje autom tico 4 redes neuronales una visi superficial 5 aprendizaje inductivo de decisi 6 introducci a la l difusa 7 introducci a las redes complejas 8 una introducci a prolog 9 pso optimizaci por enjambres de part 10 entrenamiento de redes neuronales mejorando el gradiente descendiente temas agentes algoritmos aprendizaje autom tico busqueda complejidad inteligencia artificial investigaci l machine learning matem ticas modelado netlogo opini simulacion universidad todas enlaces computaci gmsc uce a i t programaci netlogo elm language haskell humanidades digitales cultureplex lab sylvadb baroqueart otros r g n c l computacional l matem tica contacto dpto ciencias de la computaci e inteligencia artificial universidad de sevilla direcci e t s i i av reina mercedes s n 41012 sevilla tfno fax despacho 48 e mail fsancho en ejercicios de pso y inicio optimizaci en el redes neuronales una visi superficial modificaci 26 de diciembre de 2018 y ha tenido 17934 vistas etiquetas utilizadas algoritmos aprendizaje autom tico inteligencia artificial netlogo una red neuronal artificial rna es un modelo matematico inspirado en el comportamiento biologico de las neuronas y en como se organizan formando la estructura del cerebro el cerebro puede considerarse un sistema altamente complejo donde se calcula que hay aproximadamente 100 mil millones neuronas en la corteza cerebral y que forman un entramado de mas de 500 billones de conexiones neuronales neurona puede llegar a tener 100 mil conexiones aunque la media se situa entre 5000 y 10000 una red neuronal artificial es un modelo matematico inspirado en el comportamiento biologico de las neuronas y en como se organizan formando la estructura del cerebro el cerebro puede considerarse un sistema altamente complejo donde se calcula que hay aproximadamente 100 mil millones neuronas en la corteza cerebral y que forman un entramado de mas de 500 billones de conexiones neuronales neurona puede llegar a tener 100 mil conexiones aunque la media se situa entre 5000 y 10000 respecto a su funcionamiento el cerebro puede ser visto como un sistema inteligente que lleva a cabo tareas de manera distinta a como lo hacen las computadoras actuales si bien estas ultimas son muy rapidas en el procesamiento de la informacion existen tareas muy complejas como el reconocimiento y clasificacion de patrones que demandan demasiado tiempo y esfuerzo aun en las computadoras mas potentes de la actualidad pero que el cerebro humano es mas apto para resolverlas muchas veces sin aparente esfuerzo ejemplo el reconocimiento de un rostro familiar entre una multitud de si bien hay distintos tipos de neuronas biologicas la imagen de la izquierda muestra un esquema simplificado del tipo mas comun y donde podemos reconocer diferentes partes el cuerpo central llamado soma que contiene el nucleo celular una prolongacion del soma el axon un conjunto de ramificaciones terminales las dendritas zonas de conexion entre una neurona y otra conocidas como sinapsis la funcion principal de las neuronas es la transmision de impulsos nerviosos estos viajan por toda la neurona comenzando por las dendritas hasta llegar a las terminaciones del axon donde pasan a otra neurona por medio de la conexion sinaptica la manera en que respondemos ante los estimulos del mundo exterior y el aprendizaje que podemos realizar del mismo esta directamente relacionado con las conexiones neuronales del cerebro y las rnas son un intento de emular este hecho modelo neuronal de mcculloch pitts el primer modelo matematico de una neurona artificial creado con el fin de llevar a cabo tareas simples fue presentado en el ano 1943 en un trabajo conjunto entre el psiquiatra y neuroanatomista warren mcculloch y el matematico walter pitts la siguiente figura muestra un ejemplo de modelo neuronal con entradas que consta de un conjunto de entradas x los pesos sinapticos w correspondientes a cada entrada una funcion de agregacion una funcion de activacion una salida las entradas son el estimulo que la neurona artificial recibe del entorno que la rodea y la salida es la respuesta a tal estimulo la neurona puede adaptarse al medio circundante y aprender de el modificando el valor de sus pesos sinapticos y por ello son conocidos como los parametros libres del modelo ya que pueden ser modificados y adaptados para realizar una tarea determinada en este modelo la salida neuronal esta dada por w x la funcion de activacion se elige de acuerdo a la tarea realizada por la neurona entre las mas comunes dentro del campo de las rnas podemos destacar usando el perceptron para clasificar clases en el plano aplicaremos el modelo neuronal de la seccion anterior para realizar tareas de clasificacion en el plano lo que solo haremos uso de dos entradas y para ello vamos a considerar que existe una entrada de peso constante 1 y valor de entrada y consideraremos como funcion de activacion a la funcion signo definida por 1 s 0 1 s 0 por lo tanto la salida neuronal estara dada en este caso por 1 w x w x b 0 1 w x w x b 0 supongamos que tenemos dos clases en el plano la clase formada por los circulos rojos y la clase formada por los circulos azules donde cada elemento de estas clases esta representado por un punto en el plano supondremos ademas que tales clases son separables linealmente es decir es posible trazar una recta que separe estrictamente ambas clases diremos que la neurona artificial clasifica correctamente las clases y si dados los pesos sinapticos y y el termino aditivo la recta con ecuacion x es una recta que separa las dos clases la ecuacion implicita de la recta es w b observese que si el punto y c entonces w b y si y c entonces w b por lo tanto dado el par y c c la neurona clasifica de la siguiente manera y c y y c y si ahora tomamos dos clases y distintas a las anteriores entonces la neurona puede no clasificar correctamente a estas clases pues la recta anterior puede no ser una recta valida para separarlas sin embargo es posible modificar los parametros anteriores y obtener nuevos parametros y de forma que la recta x si sirva como recta de separacion entre ellos el proceso por el cual la neurona pasa de los parametros w a los parametros se conoce como aprendizaje este proceso es el que permite modificar los parametros libres con el fin de que la neurona se adapte y sea capaz de realizar diversas tareas el metodo de aprendizaje que detallaremos a continuacion y que utilizaremos para adaptar los parametros libres con el fin de clasificar correctamente las clases y se conoce como metodo de error correccion para aplicarlo es necesario un conjunto de entrenamiento un instructor valores iniciales w b arbitrarios de los parametros libres el conjunto de entrenamiento es definido por c c el entrenamiento consiste en lo siguiente el instructor toma un elemento y al azar y presenta este a la neurona si la neurona clasifica mal este punto es decir si la salida de la neurona es cuando y c o cuando y c entonces se aplica la siguiente correccion a los parametros libres iniciales w d x w d y b donde el valor de se obtiene de la siguiente manera 1 y 1 y y c 1 y y y c si la neurona clasifica bien el punto y entonces no se realiza ninguna correccion el procedimiento se repite pasando a la neurona otro punto del conjunto y usando los ultimos parametros w corregidos los nuevamente si la neurona clasifica mal el punto entonces se aplica una correccion similar a la anterior esta tarea se repite con todos los puntos del conjunto si en el proceso hubo correcciones entonces el procedimiento es repetido nuevamente con todos los puntos de el entrenamiento termina cuando la neurona clasifica correctamente todos los elementos del conjunto de entrenamiento este procedimiento converge es decir en un numero finito de pasos es posible obtener los parametros finales que separan entre si los conjuntos un modelo neuronal utilizado para clasificacion cuya salida esta dada de la forma anterior y que utiliza el metodo de error correccion para modificar sus parametros libres se conoce como perceptron nombre deriva de la palabra en ingles estas neuronas pueden agruparse formando una rna conocida como perceptron multiple el perceptron multicapa un caso particular de perceptron multiple se puede formar organizando sus neuronas en capas asi tenemos la capa de entrada formada por las entradas a la red la capa de salida formada por las neuronas que constituyen la salida final de la red y las capas ocultas formadas por las neuronas que se encuentran entre los nodos de entrada y de salida una rna puede tener varias capas ocultas o no tener ninguna de ellas las conexiones sinapticas flechas que llegan y salen de las indican el flujo de la senal a traves de la red y tienen asociadas un peso sinaptico correspondiente si la salida de una neurona va dirigida hacia dos o mas neuronas de la siguiente capa cada una de estas ultimas recibe la salida neta de la neurona anterior la cantidad de capas de una rna es la suma de las capas ocultas mas la capa de salida en el caso de existir capas ocultas nos referimos a la rna como un perceptron multicapa el problema habitual con este tipo de redes multicapa es el de dados un conjunto de datos ya clasificados de los que se conoce la salida deseada proporcionar los pesos adecuados de la red para que se obtenga una aproximacion correcta de las salidas si la red recibe unicamente los datos de entrada a mediados de los anos 80 se ofrecio un algoritmo llamado de propagacion hacia atras que aproxima en muchos casos los pesos a partir de los datos objetivo este algoritmo de entrenamiento de la red se puede resumir muy brevemente en los siguiente puntos empezar con unos pesos sinapticos cualesquiera elegidos al introducir datos de entrada la capa de elegidos al azar entre el conjunto de datos de entrada que se van a usar para el entrenamiento dejar que la red genere un vector de datos de salida hacia comparar la salida generada por al red con la salida deseada la diferencia obtenida entre la salida generada y la deseada error se usa para ajustar los pesos sinapticos de las neuronas de la capa de salidas el error se propaga hacia atras hacia la capa de neuronas anterior y se usa para ajustar los pesos sinapticos en esta capa se continua propagando el error hacia atras y ajustando los pesos hasta que se alcance la capa de entradas este proceso se repetira con los diferentes datos de entrenamiento entre las diversas tareas en las que una rna puede aplicarse podemos mencionar la clasificacion lineal y no lineal de una cantidad arbitraria c de clases regresion lineal y no lineal analisis de series temporales control de procesos robotica optimizacion de funciones procesamiento de senales etc para saber mas universidad carlos iii redes neuronales wikipedia redes neuronales artificiales xataka redes neuronales artificiales qu son y porqu est n volviendo introducci a las redes neuronales artificiales aplicadas tambi te puede interesar 1 clasificaci supervisada y no supervisada 2 algoritmos de hormigas y el problema del viajante 3 introducci al aprendizaje autom tico 4 redes neuronales una visi superficial 5 aprendizaje inductivo de decisi 6 introducci a la l difusa 7 introducci a las redes complejas 8 una introducci a prolog 9 pso optimizaci por enjambres de part 10 entrenamiento de redes neuronales mejorando el gradiente descendiente por favor activa javascript para ver los comentarios proporcionado por disqus ejercicios de pso y inicio optimizaci en el libro de netlogo ingl y espa el libro para aprender a programar y modelar con netlogo recorrido a lo largo de 16 cap que va desde los fundamentos b sicos de programaci hasta los usos m s avanzados ejercicios propuestos en cada cap y ejemplos completamente resueltos videocurso de netlogo en el libro una herramienta de con m s de 60 videos que recorren los temas principales contacto dpto ciencias de la computaci e inteligencia artificial universidad de sevilla direcci e t s i i av reina mercedes s n 41012 sevilla tfno fax despacho 48 e mail fsancho en y dicen saber tiene de ciencias lo que tiene de matem h poincar estudio profundo de la naturaleza es la fuente m s f de descubrimientos matem ticos j fourier hay certidumbre all donde no es posible aplicar ninguna de las ciencias matem ticas ni ninguna de las basadas en las matem ticas leonardo da vinci theme for pivotx by windmill web work in 2009 released under the simple public license 