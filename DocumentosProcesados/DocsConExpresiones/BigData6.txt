 qu herramientas necesitas para iniciarte en big data inlab fib press x to close pasar al contenido principal contacto catal espa english soluciones empresas soluciones para empresas especializaci colaboradores formaci proyectos herramientas citscale programa talent laboratorio docente blog inlab fib conoce inlab fib equipo formulario de b search this site qu herramientas necesitas para iniciarte en big data enviado por juan salmeron en vie 15 01 2016 13 54 introducci desde la creaci de internet y cada vez m s se ha contado con datos generados por infinidad de aplicaciones y que tenemos a nuestro alcance esperando a ser usados anta tener y consumir todo este ingente material se pod volver una tarea pr cticamente imposible o inviable tanto econ como tecnol esto limitaba el uso de la informaci a aquella que era m s relevante y punto vamos a ver en que herramientas podemos iniciarnos para solventar este handicap y sacar el m ximo valor a nuestros datos herramientas open source y que cualquiera tiene a su disposici el ecosistema hadoop hardware hoy en d tenemos a nuestro alcance el poder consumir esta informaci sin necesidad de contar con un car supercomputador en nuestro trastero podemos llegar a hacer pruebas con sistemas de 8 de ram y unos cuantos gb de disco duro en un entorno de producci se usa comodity hardware es decir m quinas que no necesitan tener un alto grado de fiabilidad y sofisticaci raid discos duros enterprise componentes redundantes m quinas de este tipo son mucho m s baratas y si se rompen ponemos otras y ya est el peso de la fiabilidad recae sobre el software tendremos esto s que dimensionar las caracter seg los requerimientos de nuestro escenario una configuraci t de un nodo de un entorno productivo podr ser una m quina con 8 24 cores 32 de ram y unos 8 12 discos hdd para introducirnos en el uso de este software no es necesario tener un cluster de m quinas potentes podremos ponernos a trastear con un cubieboard cluster unas simples vm s en nuestro pc o con alguna vm como la cloudera quickstart vm con todo ya montado que sirve justamente para aprender motivaci antes de nada dejemos clara una cosa y no nos enga big data es para tratar con grandes vol de datos big data aparece cuando decidimos dejar de quedarnos con lo que era m s relevante y pasar a quedarnos con todo toda informaci sirve en alg momento y nos puede permitir ver cosas que con solamente no podemos llegar a ver y que en muchas ocasiones nos puede aportar mucho valor como dec hoy en d se ha vuelto factible tener mucha informaci y ser capaz de consumirla pero tambi hay que entender cuando tiene sentido usar herramientas big data y cuando no si tenemos un volumen alto de datos y tenemos que lidiar con gigas y gigas de datos alguna magnitud estar bien usar estas herramientas de no ser as tambi podemos hacer uso de todo esto pero matar moscas a ca quiz s no es tan adecuado aunque sea la moda la base hablar de big data es hablar de hadoop y todo lo que lo rodea vamos a ver qu es hadoop hadoop se sustenta en la forma en la que almacena y accede a los datos hadoop est formado por hdfs y mapreduce la combinaci de estos dos permite que los datos est replicados y distribuidos por n nodos beneficiando la capacidad de acceso a grandes vol cuando queremos ejecutar alguna operaci sobre estos datos distribuidos hadoop se encarga de procesar cada porci de los datos en el nodo que los contiene de esta forma se aprovecha la localidad de tener los datos cerca de donde se van a procesar y permite escalar de forma casi lineal si queremos crecer en capacidad a m s nodos y listo del almacenamiento se encarga hdfs y del procesamiento mapreduce complementos b sicos con hdfs y mapreduce tenemos la capacidad b sica de almacenar datos en crudo y realizar procesos en paralelo abstray de la complejidad de este tipo de computaci ahora bien podemos utilizar otras herramientas encima de hadoop que nos potencian estas capacidades todo depender de nuestras necesidades estos son los dos m s t hdfs es el filesystem en el que se basa hadoop este sistema de ficheros se basa en una arquitectura master slave donde los masternodes coordinan a los datanodes que son aquellos donde se guarda la informaci los datos en hdfs se distribuyen por los diferentes datanodes en particiones del fichero original asegurando que cada una de estas particiones est replicada en un nivel de replicaci definido por tanto no necesitamos disponer de sistemas con raid si un disco se estropea hdfs autom ticamente replica muy r pidamente todas las particiones que estaban en este disco en todo el resto de datanodes yarn mapreduce yarn es la evoluci de mapreduce para hadoop 2 0 la funci de yarn en hadoop es la de proporcionar un entorno que gestione los recursos para realizar trabajos de computaci yarn se ocupa de distribuir el trabajo a hacer teniendo en cuenta donde est n los datos a procesar adem s de gestionar las propias ejecuciones de los programas con yarn podemos separar el sistema de ficheros del sistema de ejecuci por tanto podemos usar hdfs sin pasar por yarn o bien usar este gestor de recursos para correr aplicaciones es el caso de la mayor de herramientas que trabajan en hbase se puede considerar base de de hadoop basado en bigtable de google proporciona la capacidad de crear tablas con millones de entradas y permite hacer accesos de lectura escritura r pida y consistentemente tambi es versionada y no relacional por lo que ofrece flexibilidad adem s es f cilmente conectable ya sea a trav de su api java o mediante web services podemos usar hbase para dar forma a nuestros datos hive es una mezcla entre mapreduce y hbase permite estructurar los datos en tablas y vistas y nos permite realizar todo tipo de consultas usando su lenguaje de querying tipo sql el hiveql para aquellos casos en los que no podamos obtener lo que queremos con hiveql podemos conectar hive con nuestros propios mappers y reducers ya que hive es muy flexible en cuanto a conectividad y se le puede conectar cualquier cosa spark es el rey que ha venido a conquistarlos a todos mientras que mapreduce realiza sus procesos sobre disco spark carga en memoria los datos y realiza operaciones entre datasets intermedios llamados rdds esto hace que su rendimiento sea brutal adem s es bastante sencillo de utilizar y tiene soporte tanto para scala como para java y python contando con librer para realizar procesamiento en micro batch machine learning grafos y sql otros complementos adem s de la suite t que hemos visto hay muchos otros productos que funcionan junto con hadoop y permiten nuevas funcionalidades seg el tipo de aplicaci usaremos unas u otras tambi existen variantes de estas herramientas adaptadas a usos espec como sparkonhbase spork rhadoop y otros muchos m s aqu ten una min clasificaci data engineering spark hive pig data discovery analytics spark impala solr data integration storage hbase kudu hdfs unified data services yarn sentry hue oozie data ingestion sqoop flume kafka hands o n hemos visto solo una pincelada de las herramientas que se usan para bigdata dominarlas es cuesti de horas y de pr ctica para practicar pod hacer uso de la vm que anteriormente os comentaba para poner en practica alguno de los muchos cursos y tutoriales que se pueden encontrar on line como este curso gratuito que te ense n desde hacer el cl sico wordcount hasta realizar tareas de analytics m s complejas tambi recomiendo encarecidamente echar mano de los cl sicos libros o reilly espec de cada tecnolog proyectos relacionados ra board de recursos para el barcelona virtual mobility lab a la barcelona smart shuttle pilot un term emocional para la docencia uoc usando learning analytics para medir el elearning big data analytics lab learning analytics learning analytics pilares art relacionados qu es la visualizaci de datos dataviz big data aplicado al deporte qu es un data scientist s en inlab fib incorpora escert inlab es miembro de este web usa cookies propias para ofrecer una mejor experiencia y servicio al continuar con la navegaci entendemos que aceptas nuestra pol de cookies inlab fib 93 401 69 41 c jordi girona 1 3 edificio 08034 barcelona inlab fib upc edu intranet sobre esta web 